{
  "Initial Steps": {
    "prefix": "steps",
    "body": [
      "// 1. create a prompt template",
      "$1",
      "// 2. choose an LLM",
      "$2",
      "// 3. parse the response",
      "$3",
      "// 4. runnable sequence (LCEL)",
      "$4",
      "// 5. invoke the chain",
      "$5",
      ""
    ],
    "description": "Starter pseudocode"
  },
  "You are a helpful assistant": {
    "prefix": ["helpfulassistant"],
    "body": [
      "`You are a helpful assistant.",
      "Answer the user's question to the best of your ability.`"
    ],
    "description": "You are a helpful assistant"
  },
  "Here are some documents": {
    "prefix": ["rag", "somedocuments", "herearesomedocuments"],
    "body": [
      "SystemMessagePromptTemplate.fromTemplate(`",
      "\tHere are some documents to help you answer the question.",
      "\tDon't use your pre-trained knowledge to answer the question.",
      "\tAlways include a full link to the meetup.",
      "\tIf the answer isn't included in the documents, say you don't know.",
      "",
      "\tDocuments:",
      "\t{documents}",
      "`)"
    ],
    "description": "You are a helpful assistant"
  },
  "Retrieval Query": {
    "prefix": ["retrievalQuery"],
    "body": [
      "retrievalQuery: `",
      "\tRETURN",
      "\t\tnode.name +':\n'+ coalesce(node.description,'') AS text,",
      "\t\tscore AS score,",
      "\t\tnode {",
      "\t\t\t.name, .rating, .urlname,",
      "\t\t\turl: 'https://feetup.com/'+ node.urlname",
      "\t\t} AS metadata",
      "`,",
    ],
    "description": "Retrieve extra information as part of the document"
  },
  "Embeddings model": {
    "prefix": ["embeddings", "constembeddings"],
    "body": [
      "const embeddings = new OllamaEmbeddings({",
        "\tmodel: 'nomic-embed-text',",
      "});",
    ]
  },
  "Create Vector Store": {
    "prefix": ["vectorstore"],
    "body": [
      "const store = await Neo4jVectorStore.fromExistingGraph(embeddings, {",
      "\turl: process.env.NEO4J_URI,",
      "\tusername: process.env.NEO4J_USERNAME,",
      "\tpassword: process.env.NEO4J_PASSWORD,",
      "\tnodeLabel: 'Group',",
      "\ttextNodeProperties: ['name', 'description'],",
      "\tindexName: 'group_embeddings',",
      "\tembeddingNodeProperty: 'embedding',",
      "\tretrievalQuery: `",
      "\t\tRETURN",
      "\t\t\tnode.name +':\\n'+ coalesce(node.description,'') AS text,",
      "\t\t\tscore AS score,",
      "\t\t\tnode {",
      "\t\t\t\t.name, .rating, .urlname,",
      "\t\t\t\turl: 'https://feetup.com/'+ node.urlname",
      "\t\t\t\t} AS metadata",
      "\t`,",
      "});"
    ],
    "description": "Create a vector store"
  },
  "LLM": {
    "prefix": ["constllm"],
    "body": "const llm = new ChatOpenAI($1)",
    "description": "Create an LLM"
  },
  "OpenAI API KEY": {
    "prefix": ["openaiapikey"],
    "body": "process.env.OPENAI_API_KEY",
    "description": "OpenAI API Key from process.env"

  },
  "Output Parser": {
    "prefix": ["constparser"],
    "body": "const parser = new StringOutputParser()",
    "description": "Parse a string"
  },
  "Output": {
    "prefix": ["constoutput"],
    "body": "const output = await chain.invoke($1)",
    "description": "Parse a string"
  },
  "Return": {
    "prefix": ["returnoutput"],
    "body": "return output",
    "description": "return output"
  }
}
